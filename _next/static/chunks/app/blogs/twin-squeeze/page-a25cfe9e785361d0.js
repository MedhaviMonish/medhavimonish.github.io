(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[630],{64641:(e,r,s)=>{Promise.resolve().then(s.bind(s,39075))},39075:(e,r,s)=>{"use strict";s.r(r),s.d(r,{default:()=>d});var a=s(95155),l=s(48173),t=s.n(l),i=s(41411);function d(){return(0,a.jsxs)("main",{className:"relative min-h-screen bg-cover bg-center bg-no-repeat bg-fixed flex justify-center items-start py-20 px-4",style:{backgroundImage:"url('/images/bg-home.png')"},children:[(0,a.jsxs)("div",{className:"w-full max-w-4xl bg-black/80 text-white p-10 rounded-xl shadow-md",children:[(0,a.jsx)(t(),{href:"/",className:"text-sm text-gray-400 hover:text-white transition block mb-4",children:"← Back to Home"}),(0,a.jsx)(t(),{href:"https://github.com/MedhaviMonish/TwinSqueeze",target:"_blank",rel:"noopener noreferrer",className:"text-blue-400 hover:underline text-base block mb-2",children:"\uD83D\uDD17 View on GitHub"}),(0,a.jsx)("h1",{className:"text-4xl font-bold text-ember mb-6",children:"TwinSqueeze: Contrastive Compression with NEFTune Regularization"}),(0,a.jsxs)("p",{className:"mb-6 leading-relaxed",children:[(0,a.jsx)("strong",{children:"TwinSqueeze"})," is a Siamese network designed to compress high-dimensional sentence embeddings (e.g., 384-dim from MiniLM) into a smaller, task-optimized vector (e.g., 32-dim) while preserving cosine similarity. This project also systematically studies ",(0,a.jsx)("strong",{children:"NEFTune"}),", a noise-based regularization technique, to improve generalization and ranking quality."]}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83C\uDFAF Goals"}),(0,a.jsxs)("ul",{className:"list-disc list-inside mb-6 text-gray-400 leading-relaxed",children:[(0,a.jsx)("li",{children:"Compress 384-dim vectors to smaller sizes (e.g., 32-dim) for latency and memory gains"}),(0,a.jsx)("li",{children:"Preserve and align cosine similarity for task-specific domains"}),(0,a.jsx)("li",{children:"Support robust RAG pipelines with noise-tolerant NEFTune-optimized vectors"})]}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"❗ Why Build TwinSqueeze?"}),(0,a.jsxs)("p",{className:"mb-6 leading-relaxed",children:["OpenAI’s 1536-dim embeddings are powerful but large and prone to spurious similarity. TwinSqueeze addresses two issues:",(0,a.jsx)("br",{}),"- High dimensionality → slow search, more memory",(0,a.jsx)("br",{}),"- Too much similarity between unrelated phrases"]}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDE80 Project Highlights"}),(0,a.jsxs)("ul",{className:"list-disc list-inside mb-6 text-gray-400 leading-relaxed",children:[(0,a.jsx)("li",{children:"3-layer MLP Siamese encoder with cosine-based loss"}),(0,a.jsx)("li",{children:"Training on STS-B from GLUE with noise regularization (NEFTune)"}),(0,a.jsx)("li",{children:"Evaluation with MSE, MAE, Pearson, Spearman"}),(0,a.jsx)("li",{children:"Visualizations: loss curves, prediction scatter plots, histograms"})]}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDD0D NEFTune Ablation Study"}),(0,a.jsx)("p",{className:"mb-6 leading-relaxed",children:"Tested with different noise scales (α) to measure ranking impact:"}),(0,a.jsx)("div",{className:"overflow-x-auto mb-6",children:(0,a.jsxs)("table",{className:"w-full text-sm text-left text-gray-400 border-collapse border border-gray-700",children:[(0,a.jsx)("thead",{className:"bg-gray-800 text-ember",children:(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"Model"}),(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"α"}),(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"MSE"}),(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"MAE"}),(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"Pearson"}),(0,a.jsx)("th",{className:"px-4 py-2 border border-gray-700",children:"Spearman"})]})}),(0,a.jsxs)("tbody",{children:[(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"Baseline"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.0"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.072"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.203"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.731"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.775"})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"Alpha 0.5"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.5"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.068"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.198"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.774"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700 font-bold text-white",children:"0.814"})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"Alpha 0.75"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.75"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.072"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.201"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.773"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700 font-bold text-white",children:"0.818"})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"Alpha 1.0"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"1.0"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.082"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.215"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.748"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.798"})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"Alpha 3.0"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"3.0"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.154"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.299"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.647"}),(0,a.jsx)("td",{className:"px-4 py-2 border border-gray-700",children:"0.762"})]})]})]})}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDCCA Visualizations"}),(0,a.jsx)("p",{className:"mb-4 leading-relaxed",children:"We compare the training loss evolution for all models, and display NEFTune-style histograms for α = 0.75. Lower training loss does not always mean better generalization — as the log-scale test loss chart shows."}),(0,a.jsx)("img",{src:"https://raw.githubusercontent.com/MedhaviMonish/TwinSqueeze/main/results/loss_comparison.png",className:"rounded shadow mb-6",alt:"Loss Curves All Alphas"}),(0,a.jsx)("img",{src:"https://raw.githubusercontent.com/MedhaviMonish/TwinSqueeze/main/results/benchmark_charts/loss_compare_alpha_0.75.png",className:"rounded shadow mb-6",alt:"Histogram NEFTune 0.75"}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDD27 Run It Yourself"}),(0,a.jsx)(i.A,{language:"bash",code:"# Install deps\npip install torch datasets sentence-transformers matplotlib\n\n# Run training\npython train_experiment.py\n\n# Evaluate all saved models\npython test_all_models.py"}),(0,a.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDCDA Learnings"}),(0,a.jsxs)("ul",{className:"list-disc list-inside mb-6 text-gray-400 leading-relaxed",children:[(0,a.jsx)("li",{children:"How NEFTune improves ranking despite noisy training"}),(0,a.jsx)("li",{children:"Why smaller vectors can still preserve semantic relevance"}),(0,a.jsx)("li",{children:"When to use cosine vs MSE loss for contrastive objectives"})]}),(0,a.jsxs)("p",{className:"mb-6 leading-relaxed",children:["For anyone building RAG agents or compressing local memory for embedded search — ",(0,a.jsx)("strong",{children:"TwinSqueeze"})," gives you full control over similarity without overloading your hardware."]}),(0,a.jsx)("p",{className:"text-gray-400 text-sm italic",children:"Inspired by the NEFTune paper \xb7 Dataset: STS-B \xb7 Backbone: MiniLM"})]}),(0,a.jsx)("button",{onClick:()=>window.scrollTo({top:0,behavior:"smooth"}),className:"fixed bottom-6 right-6 z-50 bg-ember text-black px-4 py-2 rounded-full shadow-lg hover:bg-orange-400 transition",children:"↑ Top"})]})}},41411:(e,r,s)=>{"use strict";s.d(r,{A:()=>d});var a=s(95155),l=s(64566),t=s(51263),i=s(12115);function d(e){let{code:r,language:s="text"}=e,[d,n]=(0,i.useState)(!1);return(0,a.jsxs)("div",{className:"relative mb-6 rounded-lg overflow-hidden",children:[(0,a.jsx)("span",{className:"absolute top-2 left-2 text-xs text-gray-300 px-2 py-0.5 rounded",children:s}),(0,a.jsx)("button",{onClick:()=>{navigator.clipboard.writeText(r),n(!0),setTimeout(()=>n(!1),1500)},className:"absolute top-2 right-2 text-xs text-black bg-ember px-2 py-1 rounded hover:bg-orange-500 transition z-10",children:d?"Copied!":"Copy"}),(0,a.jsx)(l.A,{language:s,style:t.hc,showLineNumbers:!0,customStyle:{padding:"1.75rem 1.25rem 0.25rem 1.25rem",fontSize:"0.9rem",background:"transparent"},children:r})]})}}},e=>{var r=r=>e(e.s=r);e.O(0,[932,441,517,358],()=>r(64641)),_N_E=e.O()}]);