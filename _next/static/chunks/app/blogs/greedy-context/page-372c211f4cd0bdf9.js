(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[551],{61386:(e,t,s)=>{Promise.resolve().then(s.bind(s,53134))},53134:(e,t,s)=>{"use strict";s.r(t),s.d(t,{default:()=>r});var n=s(95155),a=s(41411);function r(){return(0,n.jsxs)("main",{className:"relative min-h-screen bg-cover bg-center bg-no-repeat bg-fixed flex justify-center items-start py-20 px-4",style:{backgroundImage:"url('/images/bg-home.png')"},children:[(0,n.jsxs)("div",{className:"w-full max-w-4xl bg-black/80 text-gray-200 p-10 rounded-xl shadow-md",children:[(0,n.jsxs)("h1",{className:"text-4xl font-bold text-ember mb-2",children:[(0,n.jsx)("a",{href:"https://github.com/MedhaviMonish/GreedyContext",target:"_blank",rel:"noopener noreferrer",className:"text-blue-400 hover:underline text-base block mb-2",children:"\uD83D\uDD17 View on GitHub"}),"GreedyContext: Shrinking LLM Memory with Semantic Graphs"]}),(0,n.jsx)("p",{className:"mb-6 leading-relaxed",children:"Traditional LLM-based chat systems send the entire conversation history to the model, even if most of it is no longer relevant. This not only increases token usage and latency but can also confuse the model during topic switches. GreedyContext solves this by constructing a semantic graph of message relationships and then extracting a minimal, meaningful subset of messages that are directly relevant to the user's latest query. So instead of blindly sending 100+ previous messages, you send only the 5–10 that matter."}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"❌ Problems with Full-History Approach"}),(0,n.jsxs)("ul",{className:"list-disc list-inside space-y-2 text-gray-400 leading-relaxed mb-6",children:[(0,n.jsx)("li",{children:"Includes outdated or unrelated messages just because they're part of the session"}),(0,n.jsx)("li",{children:"Treats topic switches as continuation — when they should be fresh starts"}),(0,n.jsx)("li",{children:"Token usage grows linearly with conversation length"}),(0,n.jsx)("li",{children:"Drives up cost, latency, and risk of hallucination"}),(0,n.jsx)("li",{children:"Requires summarization layers or external memory management or custom memory modules"}),(0,n.jsx)("li",{children:"Makes it unclear which messages actually shaped the response"})]}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"✅ GreedyContext Advantages"}),(0,n.jsxs)("ul",{className:"list-disc list-inside space-y-2 text-gray-400 leading-relaxed mb-6",children:[(0,n.jsx)("li",{children:"Strips out irrelevant branches and topic switches — treating each as a fresh intent"}),(0,n.jsx)("li",{children:"Keeps only semantically linked messages, not just recent ones"}),(0,n.jsx)("li",{children:"Reduces tokens by 50–90%, slashing cost and improving focus"}),(0,n.jsx)("li",{children:"Avoids summarization yet keeps outputs coherent"}),(0,n.jsx)("li",{children:"Less LLM confusion = fewer hallucinations and context drift"}),(0,n.jsx)("li",{children:"Plug-and-play with any LLM — no infra or architecture change needed"})]}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDCCC A Simple Example"}),(0,n.jsx)("p",{className:"mb-6 leading-relaxed",children:"You can pass both user and assistant messages into GreedyContext and let it trace the most relevant semantic path backward from the latest query:"}),(0,n.jsx)(a.A,{language:"python",code:'from semantic_context_graph import SemanticContextGraph\n\nchat_messages = [\n    {"role": "user", "content": "How do I start preparing for a career in robotics?"},\n    {"role": "assistant", "content": "You can begin with mechanical basics, then move into programming and embedded systems."},\n    {"role": "user", "content": "Which language is preferred—C++ or Python?"},\n    {"role": "assistant", "content": "Python is great for prototyping, but C++ is essential for performance-critical robotics."},\n    {"role": "user", "content": "Any tips on improving productivity while studying?"},\n    {"role": "assistant", "content": "Use Pomodoro timers and remove distractions."},\n    {"role": "user", "content": "What are some good home workouts without equipment?"},\n    {"role": "assistant", "content": "Bodyweight exercises like push-ups, squats, and planks work great."},\n    {"role": "user", "content": "Can you give me a quick vegetarian recipe?"},\n    {"role": "assistant", "content": "Try stir-fried veggies with tofu and rice."},\n    {"role": "user", "content": "What is quantum entanglement in simple terms?"}\n]\n\n# Recommended: use mode=\'cross\' for better semantic accuracy\ngraph = SemanticContextGraph(chat_messages, model_name="cross-encoder/stsb-roberta-base", mode="cross")\ngraph.build_graph(threshold=0.2)\n\npath = graph.greedy_path(start_node=len(chat_messages), goal_node=1)\nused_ids, relevant_messages = graph.extract_relevant_messages(path)\n\nfor msg in relevant_messages:\n    print(f"{msg[\'role\'].upper()}: {msg[\'content\']}")'}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83E\uDDEA Output: Final Subset of Context"}),(0,n.jsx)(a.A,{language:"text",code:"USER: What is quantum entanglement in simple terms?"}),(0,n.jsx)("p",{className:"mb-6 leading-relaxed",children:"Since this question starts a new topic, GreedyContext correctly filters out all unrelated prior messages and returns only the final user query — reducing token usage and improving clarity."}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDDBC️ Visualizing the Greedy Path"}),(0,n.jsx)("p",{className:"mb-4 leading-relaxed",children:"The red path below shows the semantic trail GreedyContext selects. Even with the same result path, thresholded graphs reduce the number of edges, which leads to faster graph processing and clearer message linkage."}),(0,n.jsx)("img",{src:"https://raw.githubusercontent.com/MedhaviMonish/GreedyContext/main/images/without_threshold.png",alt:"GreedyContext path visualization",width:600,className:"rounded shadow mb-6"}),(0,n.jsx)("img",{src:"https://raw.githubusercontent.com/MedhaviMonish/GreedyContext/main/images/with_threshold.png",alt:"GreedyContext path visualization",width:600,className:"rounded shadow mb-6"}),(0,n.jsx)("h2",{className:"text-2xl font-bold text-ember mb-2",children:"\uD83D\uDCA1 Final Tip"}),(0,n.jsxs)("p",{className:"mb-6 leading-relaxed",children:["For best results, use a threshold (e.g. 0.2) to ignore weak links. It trims unnecessary edges and lets the greedy algorithm return a cleaner and more focused message subset.",(0,n.jsx)("br",{}),(0,n.jsx)("br",{}),"\uD83D\uDCCC ",(0,n.jsx)("strong",{children:"CrossEncoder is recommended"})," for better direction-aware relevance.",(0,n.jsx)("br",{}),"\uD83D\uDCAC Bonus: No database, no summarization — just plug this into your LLM chain."]})]}),(0,n.jsx)("button",{onClick:()=>window.scrollTo({top:0,behavior:"smooth"}),className:"fixed bottom-6 right-6 z-50 bg-ember text-black px-4 py-2 rounded-full shadow-lg hover:bg-orange-400 transition",children:"↑ Top"})]})}},41411:(e,t,s)=>{"use strict";s.d(t,{A:()=>o});var n=s(95155),a=s(64566),r=s(51263),i=s(12115);function o(e){let{code:t,language:s="text"}=e,[o,l]=(0,i.useState)(!1);return(0,n.jsxs)("div",{className:"relative mb-6 rounded-lg overflow-hidden",children:[(0,n.jsx)("span",{className:"absolute top-2 left-2 text-xs text-gray-300 px-2 py-0.5 rounded",children:s}),(0,n.jsx)("button",{onClick:()=>{navigator.clipboard.writeText(t),l(!0),setTimeout(()=>l(!1),1500)},className:"absolute top-2 right-2 text-xs text-black bg-ember px-2 py-1 rounded hover:bg-orange-500 transition z-10",children:o?"Copied!":"Copy"}),(0,n.jsx)(a.A,{language:s,style:r.hc,showLineNumbers:!0,customStyle:{padding:"1.75rem 1.25rem 0.25rem 1.25rem",fontSize:"0.9rem",background:"transparent"},children:t})]})}}},e=>{var t=t=>e(e.s=t);e.O(0,[432,441,517,358],()=>t(61386)),_N_E=e.O()}]);